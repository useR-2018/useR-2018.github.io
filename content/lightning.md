+++
title = "Talk Schedule"
+++

**The talks will take place on 11-13 July 2018 (click the interested talk for its abstract). A datatable version is provided [here](../schedule-dt.html), if you're looking for a more easy-to-search & R-oriented format.** Information for presenters is [here](../presenter.html).

<!-- Tab links -->
<div class="tab">
  <button class="tablinks" onclick="openWday(event, 'Wednesday')" id="defaultOpen">Wednesday (July 11)</button>
  <button class="tablinks" onclick="openWday(event, 'Thursday')">Thursday (July 12)</button>
  <button class="tablinks" onclick="openWday(event, 'Friday')">Friday (July 13)</button>
</div>

<!-- Tab content -->
<div id="Wednesday" class="tabcontent">
  <table id="reg-sum">
    <col width="40"> <col width="40"> <col width="40"> <col width=40"> <col width="280"> <col width="40">
    <th>Time</th> <th>Session</th> <th>Presenter</th> <th>Venue</th> <th>Title</th> <th>Keywords</th>

    
    

  </table>
</div>

<div id="Thursday" class="tabcontent">
  <table id="reg-sum">
    <col width="40"> <col width="40"> <col width="40"> <col width=40"> <col width="280"> <col width="40">
    <th>Time</th> <th>Session</th> <th>Presenter</th> <th>Venue</th> <th>Title</th> <th>Keywords</th>

    
    <tr class="clickable" data-toggle="collapse" id="82" data-target=".82collapsed">  <td>14:00</td>  <td>Lightning talk</td>  <td>Tom Elliott</td>  <td>TBD</td>  <td>Historical data based priors for better bus arrival-time prediction</td>  <td>models, data mining, applications, space/time, big data</td></tr><tr class="collapse out budgets 82collapsed">  <td colspan="6">We have been developing a real-time bus arrival-time prediction framework, which so far relies solely on real-time data. However, we believe we can improve predictions (especially long-range, 20+ minutes) by incorporating historical data into the priors. This is especially useful in locations with infrequent buses, or before and after peak hour when travel times increase and decrease, respectively. Using a years' worth of GPS location data from buses in Auckland, New Zealand, we explore various models to develop time-dependent priors for bus travel time.</td></tr><tr class="clickable" data-toggle="collapse" id="92" data-target=".92collapsed">  <td>14:00</td>  <td>Lightning talk</td>  <td>Jono Tuke</td>  <td>TBD</td>  <td>Pachinko prediction</td>  <td>models, data mining</td></tr><tr class="collapse out budgets 92collapsed">  <td colspan="6">Social media is a great way for people to meet, chat and organise lunch, but it can also be used to meet, chat and organise protests. In this talk, I will explain how to use a Bayesian framework to predict social unrest from social media using Twitter as an example. So far so good, Bayesian modelling of Twitter data - but this is not that talk. How do you explain your modelling to the end-user? Not only that, but get them involved in the modelling?So let me show you how we used jam jars, coloured marbles, and the idea of Pachinko to explain our models to our collaborators, and how this started a conversation that lead to better models.</td></tr><tr class="clickable" data-toggle="collapse" id="146" data-target=".146collapsed">  <td>14:00</td>  <td>Lightning talk</td>  <td>Elvina Viennet</td>  <td>TBD</td>  <td>Uncertainty and sensitivity analyses: application to modelling the reproduction number of an infectious disease</td>  <td>models, performance</td></tr><tr class="collapse out budgets 146collapsed">  <td colspan="6">The usefulness of any model depends on the accuracy and reliability of its output. Uncertainty (UA) and sensitivity analyses (SA) are two approaches integral to the modelling process. UA enables to describe the range of possible outputs that derives from uncertainty in inputs, while SA enables a description of how sensitive the outcome variables are to inputs variation. These analyses allow for the identification of which parameters are important in explaining the outcome variable.Letâ€™s consider a model for epidemic potential of Zika virus in Australia. To build this model we included input parameters that dictate the dynamics of disease transmission, leading to an output variable that describes how likely an outbreak can occur at time (t). We undertook the simple steps of i) UA, using a latin hypercube sampling method to generate 100 000 samples of the epidemic potential, and of ii) SA using the Partial Rank Correlation Coefficient analysis, to determine the statistical relationships between each input parameter and the epidemic potential while the other input parameters are kept constant.An overview of UA and SA in the context of infectious diseases modelling will be presented.</td></tr><tr class="clickable" data-toggle="collapse" id="176" data-target=".176collapsed">  <td>14:00</td>  <td>Lightning talk</td>  <td>Mark Wohlers</td>  <td>TBD</td>  <td>Deep Learning with Keras R to model Spectral Data.</td>  <td>algorithms, models</td></tr><tr class="collapse out budgets 176collapsed">  <td colspan="6">As deep learning has become more and more popular, TensorFlow has emerged as one of the dominant frameworks in the space. Keras, which runs on top of TensorFlow as well as other popular frameworks, is a high-level Python-based API with a user-friendly interface, large community, and clear documentation including an ever increasing number of examples.  Recently the Keras R interface became available, making training deep learning models in R very accessible by connecting to this large resource. This R package also makes installing dependencies relatively straightforward, although some manual installations are still required.We give an overview of our experiences in learning to train deep learning models in R, starting with more basic examples before moving to applying on our own Near-infrared spectroscopy (NIRS)-based dataset. This involved firstly training Convolutional Neural Networks, as suggested by Bjerrum et al. (2017) and then experimenting with other architectures such as LSTM networks.The implementation was carried out using Keras with the TensorFlow gpu backend while optimisation of the various hyperparameters used the RBayesianOptimization package.</td></tr><tr class="clickable" data-toggle="collapse" id="206" data-target=".206collapsed">  <td>14:00</td>  <td>Lightning talk</td>  <td>Saras Windecker</td>  <td>TBD</td>  <td>The zoon R package for reproducible and shareable species distribution modelling</td>  <td>models, reproducibility, community/education</td></tr><tr class="collapse out budgets 206collapsed">  <td colspan="6">The rapid growth of species distribution modelling (SDM) as an ecological discipline has resulted in a large and diverse set of methods and software for constructing and evaluating SDMs. The disjointed nature of the current SDM research environment hinders evaluation of new methods, synthesis of current knowledge and the dissemination of new methods to SDM users. The zoon r package aims to overcome these problems by providing a modular framework for constructing reproducible SDM workflows. Zoon modules are interoperable snippets of r code, each carrying a SDM method that zoon combines into a single analysis object. Rather than defining these modules, zoon draws modules from an open, version-controlled online repository. zoon makes it easy for SDM researchers to contribute modules to this repository, enabling others to rapidly deploy new methods in their own workflows or to compare alternative methods. Each workflow object created by zoon is a rerunnable record of the data, code and results of an entire SDM analysis. This can then be easily shared, scrutinised, reproduced and extended by the whole SDM research community.</td></tr>
    
    

  </table>
</div>

<div id="Friday" class="tabcontent">
  <table id="reg-sum">
    <col width="40"> <col width="40"> <col width="40"> <col width=40"> <col width="280"> <col width="40">
    <th>Time</th> <th>Session</th> <th>Presenter</th> <th>Venue</th> <th>Title</th> <th>Keywords</th>

    
    

  </table>
</div>

<br>
